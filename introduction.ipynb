{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ca6ea66c409e98",
   "metadata": {},
   "source": [
    "# Generative Agents\n",
    "\n",
    "This notebook serves as an introduction to the reposetory, explaining the basic structure of the generative agents and showcasing their performance in \n",
    "simple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924bfd7f47c6f16",
   "metadata": {},
   "source": [
    "Generative Agents are AI agents that use an underlying LLM to react to a current observation that is provided to the in text form.\n",
    "Due to a memory module observations and actions by the agent are stored and can be used for later decision making, allowing the agent to generate complex emerging behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a8accd6d74d",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "- Install the required libraries using the gen_agents.yml file\n",
    "- Create a text file **api_token.txt** that contains the openAI api key"
   ]
  },
  {
   "cell_type": "code",
   "id": "60381896e444ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:52:46.341308Z",
     "start_time": "2024-05-29T13:52:46.336885Z"
    }
   },
   "source": [
    "import os\n",
    "# skip the reading of the file if you already have an environment variable under OPENAI_API_KEY\n",
    "with open('api_token.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "e15f9e6d30b0acec",
   "metadata": {},
   "source": [
    "## Creating an Agent\n",
    "\n",
    "A generative agents consist of 3 modules: the agent, the longterm memory and a shortterm memory.\n",
    "\n",
    "Lets create an agent step by step. Afterwards we will use a more convenient method that requires less code."
   ]
  },
  {
   "cell_type": "code",
   "id": "51e0c1499c0883e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:52:46.834575Z",
     "start_time": "2024-05-29T13:52:46.831134Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from memory import GenerativeAgentMemory\n",
    "from gen_agent import GenerativeAgent\n",
    "from short_term_memory import ShortTermMemory\n",
    "import faiss\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "60d366424f5af307",
   "metadata": {},
   "source": [
    "### LTM Module\n",
    "First we create the LTM module. \n",
    "At the core of the module is an LLM embedding vectorstore from the faiss library\n",
    "This allows the recall of related memories to a given observation.\n",
    "Around the vectorstore wraps a langchain **TimeWeightedVectorStoreRetriever**\n",
    "Relevant memories are retrieved according to 3 factors:\n",
    "- Embedding distance\n",
    "- Recency (More recent -> higher chance of recall)\n",
    "- Overall importance of memory (assigned at memory creation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353742566f9526",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "cbd681acd28be43e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:52:47.104646Z",
     "start_time": "2024-05-29T13:52:46.958607Z"
    }
   },
   "source": [
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    # Initialize the vectorstore as empty\n",
    "    # Never questioned this embedding size but it is pretty random\n",
    "    embedding_size = 1536\n",
    "    # faiss index from the faiss library\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "\n",
    "\n",
    "    # This function converts the euclidean norm of normalized embeddings\n",
    "    # (0 is most similar, sqrt(2) most dissimilar)\n",
    "    #  to a similarity function (0 to 1)\n",
    "    # ie. with embeddings normalized to [-1,1] max euclidean distance is sqrt(2)\n",
    "    def relevance_score_fn(score: float) -> float:\n",
    "        \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "        return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "    # FAISS is langchain wrapper for a faiss index\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model,\n",
    "        index,\n",
    "        InMemoryDocstore({}),\n",
    "        {},\n",
    "        relevance_score_fn=relevance_score_fn,\n",
    "    )\n",
    "    # k controls the maximum number of documents retrieved per call\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
    "    )\n",
    "\n",
    "\n",
    "# specify the LLM from the openai API used to rank memory importance\n",
    "# set verbose=True to see what is going on under the hood\n",
    "ltm_config = {\n",
    "    'llm_string': 'gpt-4-0125-preview',\n",
    "    'verbose': True,\n",
    "}\n",
    "\n",
    "\n",
    "memory_retriever = create_new_memory_retriever()\n",
    "long_term_memory = GenerativeAgentMemory(memory_retriever=memory_retriever, **ltm_config)\n",
    " "
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "49e90df1224313fd",
   "metadata": {},
   "source": [
    "Passing the memory_retriever is not obligatory. The ltm module will create one with the default settings shown here. <br>\n",
    "For customization create a retriever and pass it. <br>\n",
    "Passing the retriever parameters to the memory module is not supported but on the TODO list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab80d7d1114f40",
   "metadata": {},
   "source": [
    "### STM Module\n",
    "The short-term memory or conversation memory is much simple.\n",
    "It keeps track of all the observations and actions by the agent in the current situation (usually a conversation)\n",
    "and provides a summary of what has happened recently.\n",
    "It also uses an underlying LMM, which constantly updates the summary of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "id": "1c3f5dd2175bcf57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:52:47.193397Z",
     "start_time": "2024-05-29T13:52:47.123309Z"
    }
   },
   "source": [
    "stm_config = {\n",
    "    'llm_string': 'gpt-4-0125-preview',\n",
    "    'verbose':True\n",
    "}\n",
    "     \n",
    "short_term_memory = ShortTermMemory(**stm_config)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "5093ba8281ba2a9f",
   "metadata": {},
   "source": [
    "### Agent Module\n",
    "The agent integrates information from STM and LTM to react to a given observation. <br>\n",
    "In addition it has fixed character traits which also influence their behavior\n",
    "First we need to define a few traits of our agent\n",
    "\n",
    "**Some notes**:\n",
    "\n",
    "Current Goal:\n",
    "This is set and not updated by the agent in the current implementation, as it is not really required for my use case. <br>\n",
    "For further projects it can be updated by a reflection prompt, where the most recent memories are reviewed\n",
    "\n",
    "Status: This is a relic from the sims like environment, not sure if its still relevant in this use case. Might be removed"
   ]
  },
  {
   "cell_type": "code",
   "id": "a087f13923dc8477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:52:47.254582Z",
     "start_time": "2024-05-29T13:52:47.249947Z"
    }
   },
   "source": [
    "agent_dict = {\n",
    "    \"name\": \"Brian\",\n",
    "    \"age\": 52,\n",
    "    \"character_traits\": \"talkative, extraverted\", \n",
    "    \"communication_style\": \"midwestern accent, prefers smalltalk\",\n",
    "    \"current_goal\": \"enjoying his weekend\",\n",
    "    \"status\": \"Works at his parents gardening company\",\n",
    "    \"initial_observations\": [\n",
    "            \"Brian lives in the small town he grew up in\",\n",
    "            \"Brian lives in an apartment next door to his parents\",\n",
    "            \"Brian works in the family business which provides gardening services\",\n",
    "            \"Brian has a close relationship with his parents\",\n",
    "            \"Brian gets purpose from and honest day of work\",\n",
    "            \"Brian is interested in football and casually plays in the local club\",\n",
    "            \"Brian is not up to date with the world news as he feels they don't have influence on his life\",\n",
    "            \"Brian plans to take over the family business at some point in his life. He has no ambitions to move away\",\n",
    "             ],\n",
    "}\n",
    " \n",
    "agent_config = {\n",
    "    'llm_string': \"gpt-4-0125-preview\",\n",
    "    'verbose': True,\n",
    "}\n",
    "agent_config.update(agent_dict)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "7793fb4b8723cf91",
   "metadata": {},
   "source": [
    "Lets create the agent"
   ]
  },
  {
   "cell_type": "code",
   "id": "524aea1afacbe2b4",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:00.182755Z",
     "start_time": "2024-05-29T13:52:47.286832Z"
    }
   },
   "source": [
    "brian = GenerativeAgent(short_term_memory=short_term_memory, long_term_memory=long_term_memory, **agent_config)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian lives in the small town he grew up in\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian lives in an apartment next door to his parents\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian works in the family business which provides gardening services\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian has a close relationship with his parents\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian gets purpose from and honest day of work\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian is interested in football and casually plays in the local club\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian is not up to date with the world news as he feels they don't have influence on his life\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian plans to take over the family business at some point in his life. He has no ambitions to move away\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "87da50530fb13f",
   "metadata": {},
   "source": [
    "Because verbose is set to True we can see the LLM calls the LTM makes upon receiving the initial observations. <br>\n",
    "Each observation or memory gets an importance ranking from 1 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f983bea",
   "metadata": {},
   "source": [
    "### Convenient Agent Creation\n",
    "\n",
    "We can also create an agent from a config file in function call.  \n",
    "You can find some premade agent configs in the folder characters."
   ]
  },
  {
   "cell_type": "code",
   "id": "0809bb1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:00.193182Z",
     "start_time": "2024-05-29T13:53:00.185514Z"
    }
   },
   "source": [
    "import json\n",
    "path = \"characters/brian.txt\"\n",
    "with open(path, 'r') as f:\n",
    "    agent_dict = json.load(f)\n",
    "\n",
    "for key, value in agent_dict.items():\n",
    "    print(f\"{key}: {value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Brian\n",
      "age: 25\n",
      "character_traits: talkative, down to earth, enjoys the simple things in live, unpolitical, not the sharpest tool in the shed\n",
      "communication_style: midwestern accent, prefers jokes and smalltalk\n",
      "appearance: casual, functionality over appearance\n",
      "status: Works at his parents company\n",
      "initial_observations: ['Brian lives in the small town he grew up in', 'Brian lives in an apartment next door to his parents', 'Brian works in the family business which provides gardening services', 'Brian has a close relationship with his parents', 'Brian gets purpose from and honest day of work', 'Brian is interested in football and casually plays in the local club', \"Brian is not up to date with the world news as he feels they don't have influence on his life\", 'Brian plans to take over the family business at some point in his life. He has no ambitions to move away', 'Brian knows Julia from their local high school. They were close friends', 'Julia moved away to a bigger city. Brian and Julia keep in contact', 'While Brian and Julia chose very different paths for their lives, they still enjoy catching up whenever they meet']\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These character files contain personal information about the agent.  \n",
    "There is a convenience function that creates characters from such a file"
   ],
   "id": "43eaf1fdf4ff81c7"
  },
  {
   "cell_type": "code",
   "id": "a3b37a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:15.647690Z",
     "start_time": "2024-05-29T13:53:00.195608Z"
    }
   },
   "source": [
    "from utils import create_agent_from_config\n",
    "agent = create_agent_from_config(path)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can also pass any additional properties of the agent, stm and ltm to the function.  \n",
    "It makes it easier to keep the personal information in the character files, while passing agent hyperparameters via the function.  \n",
    "However properties passed to the function will take precedence if the same property is specified in the character file.\n",
    "\n"
   ],
   "id": "25869b9612fa880f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:27.870488Z",
     "start_time": "2024-05-29T13:53:15.654991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ltm_config = {\n",
    "    'llm_string': 'gpt-4-0125-preview',\n",
    "    'verbose': True,\n",
    "}\n",
    "\n",
    "stm_config = {\n",
    "    'llm_string': 'gpt-4-0125-preview',\n",
    "    'verbose' : True\n",
    "}\n",
    "\n",
    "agent_config = {\n",
    "    'llm_string': \"gpt-4-0125-preview\",\n",
    "    'verbose': True,\n",
    "}\n",
    "agent_2 = create_agent_from_config(path, agent_config, ltm_config, stm_config)\n"
   ],
   "id": "b6fc75bb3fceb8d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian lives in the small town he grew up in\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian lives in an apartment next door to his parents\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian works in the family business which provides gardening services\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian has a close relationship with his parents\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian gets purpose from and honest day of work\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian is interested in football and casually plays in the local club\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian is not up to date with the world news as he feels they don't have influence on his life\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian plans to take over the family business at some point in his life. He has no ambitions to move away\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian knows Julia from their local high school. They were close friends\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Julia moved away to a bigger city. Brian and Julia keep in contact\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: While Brian and Julia chose very different paths for their lives, they still enjoy catching up whenever they meet\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "8eaf776ec5191fdf",
   "metadata": {},
   "source": [
    "## Interacting with Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b8942f9ae377f",
   "metadata": {},
   "source": [
    "Observations or memories can also be added manually"
   ]
  },
  {
   "cell_type": "code",
   "id": "c21efb16ad9f530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:29.034871Z",
     "start_time": "2024-05-29T13:53:27.875878Z"
    }
   },
   "source": [
    "# the return value is not relevant\n",
    "brian.long_term_memory.add_memory(\"Brian met Nion last weekend at a football game where they drank a beer together\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Respond with a single integer.\n",
      "Memory: Brian met Nion last weekend at a football game where they drank a beer together\n",
      "Rating: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['7ca1b48e-ef32-4402-8c4e-078d6ce85fad']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "c9b21478",
   "metadata": {},
   "source": [
    "Now we can for example ask Brain a question.\n",
    "Generate dialogue response generates a reaction and indicates whether the agent stays in the conversation or says Goodbye"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ef66c54073bb3aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:54.507057Z",
     "start_time": "2024-05-29T13:53:29.040683Z"
    }
   },
   "source": [
    "observation = 'Tom says How What do you think about Nion?'\n",
    "stay_in_dialogue, observation = brian.generate_dialogue_response(observation)\n",
    "print(observation)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:memory:Fetching relevant memories for given queries\n",
      "INFO:memory:queries: [\"Brian's core characteristics\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In _generate_reaction: Get current agent summary\n",
      "In get_summary: Compute new agent summary\n",
      "In _compute_agent_summary: \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHow would you summarize Brian's core characteristics given the following statements:\n",
      "- [May 29, 2024, 03:52 PM] Brian has a close relationship with his parents\n",
      "- [May 29, 2024, 03:52 PM] Brian gets purpose from and honest day of work\n",
      "- [May 29, 2024, 03:52 PM] Brian lives in the small town he grew up in\n",
      "- [May 29, 2024, 03:52 PM] Brian works in the family business which provides gardening services\n",
      "- [May 29, 2024, 03:52 PM] Brian is interested in football and casually plays in the local club\n",
      "- [May 29, 2024, 03:52 PM] Brian plans to take over the family business at some point in his life. He has no ambitions to move away\n",
      "- [May 29, 2024, 03:52 PM] Brian lives in an apartment next door to his parents\n",
      "- [May 29, 2024, 03:52 PM] Brian is not up to date with the world news as he feels they don't have influence on his life\n",
      "- [May 29, 2024, 03:53 PM] Brian met Nion last weekend at a football game where they drank a beer together \n",
      "Do not embellish.\n",
      "\n",
      "Summary: \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "In _generate_reaction: Summarize related memories\n",
      "In summarize_related_memories: Get entity from Observation\n",
      "In _get_entity_from_observation: \n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mWho or what is talking or acting in the following observation: Tom says How What do you think about Nion?\n",
      "Answer with a single expression\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer: Entity  is Tom\n",
      "In summarize_related_memories: Get entity action\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mDescribe in one sentence what Tom is doing in the following observation? Tom says How What do you think about Nion?\n",
      "Tom is...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:memory:Fetching relevant memories for given queries\n",
      "INFO:memory:queries: ['What is the relationship between Brian and Tom', \"Tom is asking for someone's opinion about Nion.\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer: Tom is asking for someone's opinion about Nion.\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "            Given the presented context from memory:\n",
      "            Provide a short summary of the relationship between Brian and Tom\n",
      "            Provide a short summary of the relevant memories regarding the observation\n",
      "            Context from memory:\n",
      "            - [May 29, 2024, 03:52 PM] Brian has a close relationship with his parents\n",
      "- [May 29, 2024, 03:52 PM] Brian gets purpose from and honest day of work\n",
      "- [May 29, 2024, 03:53 PM] Brian met Nion last weekend at a football game where they drank a beer together\n",
      "- [May 29, 2024, 03:52 PM] Brian lives in an apartment next door to his parents\n",
      "- [May 29, 2024, 03:52 PM] Brian works in the family business which provides gardening services\n",
      "- [May 29, 2024, 03:52 PM] Brian plans to take over the family business at some point in his life. He has no ambitions to move away\n",
      "- [May 29, 2024, 03:52 PM] Brian lives in the small town he grew up in\n",
      "- [May 29, 2024, 03:52 PM] Brian is interested in football and casually plays in the local club\n",
      "- [May 29, 2024, 03:52 PM] Brian is not up to date with the world news as he feels they don't have influence on his life\n",
      "- [May 29, 2024, 03:53 PM] Brian met Nion last weekend at a football game where they drank a beer together\n",
      "- [May 29, 2024, 03:52 PM] Brian plans to take over the family business at some point in his life. He has no ambitions to move away\n",
      "- [May 29, 2024, 03:52 PM] Brian has a close relationship with his parents\n",
      "- [May 29, 2024, 03:52 PM] Brian is not up to date with the world news as he feels they don't have influence on his life\n",
      "- [May 29, 2024, 03:52 PM] Brian is interested in football and casually plays in the local club\n",
      "- [May 29, 2024, 03:52 PM] Brian gets purpose from and honest day of work\n",
      "- [May 29, 2024, 03:52 PM] Brian works in the family business which provides gardening services\n",
      "- [May 29, 2024, 03:52 PM] Brian lives in the small town he grew up in\n",
      "- [May 29, 2024, 03:52 PM] Brian lives in an apartment next door to his parents\n",
      "            Observation:\n",
      "            Tom says How What do you think about Nion?\n",
      "            Only answer based on the provided memories and DO NOT assume anything else.\n",
      "            Answer with a maximum of two sentences for each point and answer in the following form\n",
      "            Relationship between Brian and Tom:...\n",
      "            Summary of relevant memories:...\n",
      "            \u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer: Relationship between Brian and Tom: There is no information provided on the relationship between Brian and Tom.\n",
      "\n",
      "Summary of relevant memories: Brian met Nion last weekend at a football game where they drank a beer together.\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mName: Brian (age: 52)\n",
      "Character traits: talkative, extraverted\n",
      "Current Goal: enjoying his weekend\n",
      "Communication Stylemidwestern accent, prefers smalltalk\n",
      "Brian is deeply rooted in his hometown and maintains a strong connection with his family, particularly his parents, living next door to them. He derives satisfaction from honest work, contributing to the family gardening business with plans to eventually take over. He enjoys football, both as a spectator and a participant in the local club. Brian is content with his local life, showing little interest in broader world affairs, believing they do not impact him. He is also sociable, making acquaintances through shared interests like football.\n",
      "It is May 29, 2024, 03:53 PM.\n",
      "Brian's status: Works at his parents gardening company\n",
      "Summary of relevant context from Brian's memory:\n",
      "Relationship between Brian and Tom: There is no information provided on the relationship between Brian and Tom.\n",
      "\n",
      "Summary of relevant memories: Brian met Nion last weekend at a football game where they drank a beer together.\n",
      "Summary of what has happened so far in the current situation or conversation:\n",
      "\n",
      "The current observation to which Brian reacts: Tom says How What do you think about Nion?\n",
      "Brian's reaction should be in line with its current goal\n",
      "Brian's reaction should be in line with the given character traits and the agents communication style\n",
      "\n",
      "What would Brian say? To end the conversation, write: [GOODBYE] Brian: \"what to say\". Otherwise to continue the conversation, write: [SAY] Brian: \"what to say next\"\n",
      "\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Tom :  How What do you think about Nion?\n",
      "Brian:  \"Oh, Nion? Nice guy, we caught up over a beer at the game last weekend. Seems like he's really into football, just like me. How about you, Tom? What's your take on him?\"\n",
      "\n",
      "New summary:\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:short_term_memory:current summary:Brian thinks Nion is a nice guy, mentioning they both enjoy football after catching up over a beer at a game last weekend. He's curious about Tom's opinion on Nion.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Brian: \"Oh, Nion? Nice guy, we caught up over a beer at the game last weekend. Seems like he's really into football, just like me. How about you, Tom? What's your take on him?\"\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "d1111ed8cd634df8",
   "metadata": {},
   "source": [
    "As verbose is set to True, we get a whole wall of text that explains what is going on under the hood. <br>\n",
    "\n",
    "- The Info messages are logged by the long-term memory and indicate for which queries relevant memories are fetched.\n",
    "    - Relevant meaning the smallest euclidean distance to the queries in embedding space \n",
    "    - The placement of the info messages are not exactt, they happen when a chain is called that uses queries to LTM\n",
    "- The green texts are the prompts for every call to the LLM\n",
    "- The white print statements are infos that indicate in which function the process currently is and what is being done\n",
    " \n",
    "Let's go through it step by step: <br>\n",
    "- First _generate_reaction is called by generate_dialogue response\n",
    "\n",
    "**Compute Agent Summary**\n",
    "\n",
    "- Then _compute agent summary is called\n",
    "    - This only happens when there is no summary at the creation of a character \n",
    "    - or if a certain amount of time has passed, therefore requiring a new summary\n",
    "    - This is controlled by agent.summary_refresh_seconds, on default it is refreshed once every hour\n",
    "- Next we see an LMM Prompt that summarizes brian's core characteristics, based on the queried memories\n",
    "    - The query is displayed in the INFO message from the LTM Module\n",
    "\n",
    "**Context from memory**\n",
    "- _summarize_related_memories is called by _generate_reaction\n",
    "    - this function provides a summary of relevant memories regarding the given observation\n",
    "- First _get_entity_from_observation is called\n",
    "    - A prompt identifies the acting entity in the observation, which should be Tom\n",
    "- Next _get_entity_action is called to describe what the entity is doing in the observation\n",
    "- This information is used to form two queries for the LTM (info message)\n",
    "    1. Regarding the relationship between the agent and the entity\n",
    "    2. Regarding the action of the entity       \n",
    "- The fetched memories are formatted in the next prompt, which summarizes the information from memory, regarding the relationship and the action of the entity\n",
    "    - Ideally this should result in no information regarding the relationship of Brain and Tom as no information is present in Memory\n",
    "    -  Regarding the action of asking about Nion, the summary should mention that Brain met him at a football game last weekend\n",
    "\n",
    "**Putting the information together**\n",
    "\n",
    "The next prompt unites all the relevant information about the character and the observation <br>\n",
    "- First there is general information about the character including the fixed personality traits and communication style <br>\n",
    "- Then comes the computed agent summary with general information about the agent <br>\n",
    "- The agents status and the current time (Might move that to the top)\n",
    "- The summarized memories about the relationship and the content of the observation\n",
    "- The summary of the conversation so far: empty in this case\n",
    "- Instructions for generating the characters reaction\n",
    "\n",
    "Now the reaction is generated <br>\n",
    "Upon finishing that chain the observation and the agents reaction are stored in the STM module, followed by a prompt that updates the summary \n",
    "using the newly added lines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43b06ab0104050",
   "metadata": {},
   "source": [
    "As that is quite a lot of text, set verbose to False now"
   ]
  },
  {
   "cell_type": "code",
   "id": "5adc1d47d523ae3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:54.520978Z",
     "start_time": "2024-05-29T13:53:54.512431Z"
    }
   },
   "source": [
    "brian.verbose = False\n",
    "brian.long_term_memory.verbose = False\n",
    "brian.short_term_memory.verbose = False"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "61d986a8e65307e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:53:54.527328Z",
     "start_time": "2024-05-29T13:53:54.523583Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "9e7659cdcdd87d4f",
   "metadata": {},
   "source": [
    "### STM to LTM Transfer\n",
    "In our example with brian our question and his reaction were store in his STM memory. <br>\n",
    "However, it was not transferred to the STM module.\n",
    "\n",
    "The transfer from STM to LTM is controlled by the beginning and end of a \"situation\". <br>\n",
    "In my use case this is usually one conversation with another character, although the boundaries of a situation can be arbitrarily set. <br>\n",
    "At the start of a situation the STM is cleared (as a precaution for some unrelated residue like our earlier question) <br>\n",
    "At the end of a situation the information in the STM is summarized and appraised by the character (and also cleared). <br>\n",
    "Summary and Appraisal are then stored in the LTM module as new memories. <br>\n",
    "This allows for the separation of more high level information for LTM and more detailed information that might only be relevant in the current situation. <br>\n",
    "It also allows the agent to reflect on the content of a situation. <br>\n",
    "\n",
    "Currently, situations are started and ended manually by calling the functions  `agent.start_situation()` and `agent.end_situation()`\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saving and Loading Agents\n",
    "\n",
    "If you want your agents to live longer than one python runtime you can save them"
   ],
   "id": "36fadd0ab001dc9e"
  },
  {
   "cell_type": "code",
   "id": "a6c58d6a92ef444d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:55:08.402182Z",
     "start_time": "2024-05-29T13:55:08.395460Z"
    }
   },
   "source": [
    "from gen_agent import GenerativeAgent\n",
    "# specify a path for the character to be stored\n",
    "path = 'saved_characters/brian_test'\n",
    "GenerativeAgent.save_instance(brian, path)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The saved agent is a folder with a config for the agent, the ltm, the stm and a file with the ltm vectorstore.\n",
    "Not every part of the agent can be serialized in the same manner. Therefore we store the configurations and the vectorstore and create a new agent object upon loading"
   ],
   "id": "ef0ddd2f52bfd0"
  },
  {
   "cell_type": "code",
   "id": "cf8e49522187dda2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:55:10.910774Z",
     "start_time": "2024-05-29T13:55:10.701026Z"
    }
   },
   "source": "! ls saved_characters/brian_test",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_dict.json  faiss_vector_store.index  ltm_dict.json  stm_dict.json\r\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you provide an already existing path it will be overwritten. Be careful when dealing with different versions of the same character.\n",
    "\n",
    "\n",
    "Now we can load the agent."
   ],
   "id": "78b1ad1e72ef3d0d"
  },
  {
   "cell_type": "code",
   "id": "b09d3c2f61d46471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T14:02:44.371235Z",
     "start_time": "2024-05-29T14:02:44.122510Z"
    }
   },
   "source": "brian_loaded = GenerativeAgent.load_instance(path)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Brian lives in the small town he grew up in', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 48, 169165), 'buffer_idx': 0}), Document(page_content='Brian lives in an apartment next door to his parents', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 49, 326200), 'buffer_idx': 1}), Document(page_content='Brian works in the family business which provides gardening services', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 50, 784044), 'buffer_idx': 2}), Document(page_content='Brian has a close relationship with his parents', metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 55, 486668), 'buffer_idx': 3}), Document(page_content='Brian gets purpose from and honest day of work', metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 56, 635097), 'buffer_idx': 4}), Document(page_content='Brian is interested in football and casually plays in the local club', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 57, 574003), 'buffer_idx': 5}), Document(page_content=\"Brian is not up to date with the world news as he feels they don't have influence on his life\", metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 58, 610787), 'buffer_idx': 6}), Document(page_content='Brian plans to take over the family business at some point in his life. He has no ambitions to move away', metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 59, 870303), 'buffer_idx': 7}), Document(page_content='Brian met Nion last weekend at a football game where they drank a beer together', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 53, 28, 697185), 'buffer_idx': 8})]\n",
      "[Document(page_content='Brian lives in the small town he grew up in', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 48, 169165), 'buffer_idx': 0}), Document(page_content='Brian lives in an apartment next door to his parents', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 49, 326200), 'buffer_idx': 1}), Document(page_content='Brian works in the family business which provides gardening services', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 50, 784044), 'buffer_idx': 2}), Document(page_content='Brian has a close relationship with his parents', metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 55, 486668), 'buffer_idx': 3}), Document(page_content='Brian gets purpose from and honest day of work', metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 56, 635097), 'buffer_idx': 4}), Document(page_content='Brian is interested in football and casually plays in the local club', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 57, 574003), 'buffer_idx': 5}), Document(page_content=\"Brian is not up to date with the world news as he feels they don't have influence on his life\", metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 58, 610787), 'buffer_idx': 6}), Document(page_content='Brian plans to take over the family business at some point in his life. He has no ambitions to move away', metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 52, 59, 870303), 'buffer_idx': 7}), Document(page_content='Brian met Nion last weekend at a football game where they drank a beer together', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2024, 5, 29, 15, 53, 39, 870172), 'created_at': datetime.datetime(2024, 5, 29, 15, 53, 28, 697185), 'buffer_idx': 8})]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Note**  \n",
    "At the moment the loading function creates a new memory retriever with the loaded Faiss index with default configurations, as langchain does not provide save or load functionality for the retrievers.\n",
    "Therefore retrievers with custom configs need to be recreated manually with the vectorstore from the automatically created default retriever."
   ],
   "id": "434058025352fdb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c2fe0bb1579a873"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
